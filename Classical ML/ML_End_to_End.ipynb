{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate dummy dataset\n",
    "np.random.seed(42)\n",
    "n_samples = 10000\n",
    "\n",
    "# Create features\n",
    "numerical_features = np.random.randn(n_samples, 3) * 10\n",
    "numerical_features[np.random.randint(0, n_samples, 500), np.random.randint(0, 3, 500)] = np.nan  # Missing values\n",
    "\n",
    "categories = ['A', 'B', 'C', 'D', 'E']\n",
    "categorical_features = np.random.choice(categories, n_samples)\n",
    "categorical_features[np.random.randint(0, n_samples, 300)] = np.nan  # Missing values\n",
    "\n",
    "text_data = np.random.choice([\"This is a sample text\", \"Another text data\", \"More random text data\"], n_samples)\n",
    "\n",
    "# Imbalanced target variable\n",
    "target_classes = ['Class_1', 'Class_2', 'Class_3', 'Class_4']\n",
    "class_distribution = [0.7, 0.2, 0.08, 0.02]\n",
    "target = np.random.choice(target_classes, n_samples, p=class_distribution)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(numerical_features, columns=[\"num_1\", \"num_2\", \"num_3\"])\n",
    "df['category'] = categorical_features\n",
    "df['text'] = text_data\n",
    "df['target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_1</th>\n",
       "      <th>num_2</th>\n",
       "      <th>num_3</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.967142</td>\n",
       "      <td>-1.382643</td>\n",
       "      <td>6.476885</td>\n",
       "      <td>B</td>\n",
       "      <td>More random text data</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.230299</td>\n",
       "      <td>-2.341534</td>\n",
       "      <td>-2.341370</td>\n",
       "      <td>A</td>\n",
       "      <td>This is a sample text</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.792128</td>\n",
       "      <td>7.674347</td>\n",
       "      <td>-4.694744</td>\n",
       "      <td>D</td>\n",
       "      <td>More random text data</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.425600</td>\n",
       "      <td>-4.634177</td>\n",
       "      <td>-4.657298</td>\n",
       "      <td>B</td>\n",
       "      <td>This is a sample text</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.419623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.249178</td>\n",
       "      <td>D</td>\n",
       "      <td>More random text data</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-3.435382</td>\n",
       "      <td>-3.940473</td>\n",
       "      <td>2.579958</td>\n",
       "      <td>A</td>\n",
       "      <td>More random text data</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>10.442918</td>\n",
       "      <td>16.029643</td>\n",
       "      <td>-2.185383</td>\n",
       "      <td>E</td>\n",
       "      <td>Another text data</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>18.248892</td>\n",
       "      <td>8.767068</td>\n",
       "      <td>-12.320085</td>\n",
       "      <td>A</td>\n",
       "      <td>More random text data</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-12.612083</td>\n",
       "      <td>-5.772879</td>\n",
       "      <td>14.446040</td>\n",
       "      <td>A</td>\n",
       "      <td>More random text data</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-5.013673</td>\n",
       "      <td>-18.923568</td>\n",
       "      <td>-2.288842</td>\n",
       "      <td>D</td>\n",
       "      <td>More random text data</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          num_1      num_2      num_3 category                   text   target\n",
       "0      4.967142  -1.382643   6.476885        B  More random text data  Class_2\n",
       "1     15.230299  -2.341534  -2.341370        A  This is a sample text  Class_1\n",
       "2     15.792128   7.674347  -4.694744        D  More random text data  Class_1\n",
       "3      5.425600  -4.634177  -4.657298        B  This is a sample text  Class_1\n",
       "4      2.419623        NaN -17.249178        D  More random text data  Class_2\n",
       "...         ...        ...        ...      ...                    ...      ...\n",
       "9995  -3.435382  -3.940473   2.579958        A  More random text data  Class_1\n",
       "9996  10.442918  16.029643  -2.185383        E      Another text data  Class_1\n",
       "9997  18.248892   8.767068 -12.320085        A  More random text data  Class_1\n",
       "9998 -12.612083  -5.772879  14.446040        A  More random text data  Class_1\n",
       "9999  -5.013673 -18.923568  -2.288842        D  More random text data  Class_1\n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "Class_1    6874\n",
       "Class_2    2109\n",
       "Class_3     820\n",
       "Class_4     197\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 5) (2000, 5)\n",
      "(8000,) (2000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-test split\n",
    "X, y = df.drop(columns=['target']), df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Impute missing values\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# One-Hot Encoding with 'Other' category handling\n",
    "ohe = OneHotEncoder(handle_unknown='infrequent_if_exist', min_frequency=0.01)  # Less frequent categories go to 'other'\n",
    "\n",
    "# Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num_1', 'num_2', 'num_3', 'category', 'text', 'target'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Column Transformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numerical_transformation', Pipeline([('imputer', num_imputer), ('scaler', scaler)]), ['num_1', 'num_2', 'num_3']),\n",
    "    ('categorical_transformation', Pipeline([('imputer', cat_imputer), ('ohe', ohe)]), ['category']),\n",
    "    ('text_transformation', tfidf, 'text')\n",
    "])\n",
    "\n",
    "# Apply transformations\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ColumnTransformer applies different transformations to different types of columns in the dataset.\n",
    "- Each transformation is defined as a tuple: ('name', transformer, columns), where:\n",
    "  \n",
    "  - name: A label for the transformation step.\n",
    "  - transformer: The actual transformation pipeline (e.g., Pipeline, TfidfVectorizer).\n",
    "  - columns: The specific columns this transformation applies to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class_1       0.69      0.59      0.64      1375\n",
      "     Class_2       0.20      0.22      0.21       422\n",
      "     Class_3       0.06      0.10      0.08       164\n",
      "     Class_4       0.01      0.03      0.02        39\n",
      "\n",
      "    accuracy                           0.46      2000\n",
      "   macro avg       0.24      0.23      0.23      2000\n",
      "weighted avg       0.52      0.46      0.49      2000\n",
      "\n",
      "F1 Macro Score: 0.2345918172837115\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "pred = model.predict(X_test_transformed)\n",
    "\n",
    "report = classification_report(y_test, pred)\n",
    "f1_macro = f1_score(y_test, pred, average='macro')\n",
    "\n",
    "# Print classification reports\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"F1 Macro Score:\", f1_macro)\n",
    "print(\"--\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Input, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "input_shape = X_train_smote.shape[1]\n",
    "output_shape = len(np.unique(y_train))\n",
    "print(input_shape)\n",
    "print(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Class_1', 'Class_2', 'Class_3', 'Class_4'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_map = {'Class_1':0, 'Class_2':1, 'Class_3':2, 'Class_4':3}\n",
    "y_train_smote_ids = np.array([dict_map[y] for y in y_train_smote])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 16ms/step - accuracy: 0.3024 - loss: 1.4774 - val_accuracy: 0.0000e+00 - val_loss: 2.6658\n",
      "Epoch 2/3\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - accuracy: 0.3333 - loss: 1.2743 - val_accuracy: 0.0000e+00 - val_loss: 2.6882\n",
      "Epoch 3/3\n",
      "\u001b[1m1100/1100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.3397 - loss: 1.2647 - val_accuracy: 0.0000e+00 - val_loss: 2.7290\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# NN Model\n",
    "inputs = Input(shape=(input_shape,))\n",
    "\n",
    "x = layers.Dense(64)(inputs)  # No activation yet\n",
    "x = layers.BatchNormalization()(x)  # Normalize before activation\n",
    "x = layers.ReLU()(x)  # Apply activation\n",
    "x = layers.Dropout(0.2)(x)  # Dropout AFTER activation\n",
    "\n",
    "x = layers.Dense(32, activation='relu')(x) # just to show that relu can also be applied here, but it is less efficient\n",
    "x = layers.BatchNormalization()(x) \n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "outputs = layers.Dense(output_shape, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy' , metrics = ['accuracy'])\n",
    "# model.compile(optimizer='adam', loss='mse' , metrics = ['mae']) # Fore regression\n",
    "\n",
    "# Train model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)              \n",
    "history = model.fit(X_train_smote, y_train_smote_ids, epochs=3, batch_size=16, verbose=1, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_transformed)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Class_1', 1: 'Class_2', 2: 'Class_3', 3: 'Class_4'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_map_inverse = {v:k for k, v in dict_map.items()}\n",
    "dict_map_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Class_2', 'Class_3', 'Class_1', ..., 'Class_1', 'Class_1',\n",
       "       'Class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.array([dict_map_inverse[y] for y in y_pred])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class_1       0.69      0.51      0.59      1375\n",
      "     Class_2       0.23      0.28      0.25       422\n",
      "     Class_3       0.07      0.20      0.11       164\n",
      "     Class_4       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.43      2000\n",
      "   macro avg       0.25      0.25      0.24      2000\n",
      "weighted avg       0.53      0.43      0.47      2000\n",
      "\n",
      "F1 Macro Score: 0.2345918172837115\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anand.thirwani/Documents/Study/AI_ML_Popular_Codes/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/anand.thirwani/Documents/Study/AI_ML_Popular_Codes/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/anand.thirwani/Documents/Study/AI_ML_Popular_Codes/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, pred, average='macro')\n",
    "\n",
    "# Print classification reports\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"F1 Macro Score:\", f1_macro)\n",
    "print(\"--\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
